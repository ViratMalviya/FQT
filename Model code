#Model.py for all the pcs
import torch
import torch.nn as nn
import pennylane as qml
import librosa
import numpy as np

torch.manual_seed(42)
np.random.seed(42)

# =====================
# MFCC EXTRACTION
# =====================
def extract_mfcc(audio_path, n_mfcc=20, max_len=100):
    y, sr = librosa.load(audio_path, sr=22050, mono=True)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)

    if mfcc.shape[1] > max_len:
        mfcc = mfcc[:, :max_len]
    else:
        mfcc = np.pad(mfcc, ((0,0),(0, max_len-mfcc.shape[1])))

    mfcc = (mfcc - mfcc.mean()) / (mfcc.std() + 1e-6)
    return mfcc.astype(np.float32)

# =====================
# QUANTUM SETUP
# =====================
n_qubits = 17
n_layers = 2
dev = qml.device("default.qubit", wires=n_qubits)

@qml.qnode(dev, interface="torch")
def qnn_circuit(inputs, weights):
    qml.AngleEmbedding(inputs, wires=range(n_qubits))
    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))
    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]

def mfcc_to_quantum_input(mfcc):
    mean = mfcc.mean(dim=1)
    std = mfcc.std(dim=1)
    stats = torch.cat([mean, std])

    if stats.shape[0] > n_qubits:
        stats = stats[:n_qubits]
    else:
        stats = torch.nn.functional.pad(stats, (0, n_qubits - stats.shape[0]))

    return stats

# =====================
# CNN MODEL
# =====================
class TargetCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)
        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)
        self.pool = nn.MaxPool2d(2)
        self.fc1 = nn.Linear(16*5*25, 64)
        self.fc2 = nn.Linear(64, 2)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.unsqueeze(1)
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = self.relu(self.fc1(x))
        return self.fc2(x)

# =====================
# QUANTUM GENERATOR
# =====================
class QuantumTrainGenerator(nn.Module):
    def __init__(self, target_model):
        super().__init__()
        self.num_params = sum(p.numel() for p in target_model.parameters())
        self.qnn_weights = nn.Parameter(torch.randn(n_layers, n_qubits) * 0.01)
        self.mapper = nn.Sequential(
            nn.Linear(n_qubits, 128),
            nn.ReLU(),
            nn.Linear(128, self.num_params)
        )

    def forward(self, mfcc_batch):
        mfcc_avg = mfcc_batch.mean(dim=0)
        q_input = mfcc_to_quantum_input(mfcc_avg)
        q_out = qnn_circuit(q_input, self.qnn_weights)
        q_out = torch.tensor(q_out, dtype=torch.float32)
        return self.mapper(q_out)

def set_target_model_params(model, flat_params):
    offset = 0
    for p in model.parameters():
        n = p.numel()
        p.data.copy_(flat_params[offset:offset+n].view(p.size()))
        offset += n




